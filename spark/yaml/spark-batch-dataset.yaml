apiVersion: sparkoperator.k8s.io/v1beta2
kind: SparkApplication
metadata:
  name: spark-batch-dataset          # ğŸ’¡ job ì´ë¦„ ë³€ê²½
  namespace: default
spec:
  type: Python
  mode: cluster
  image: dwnusa/spark:v3.5.4-amd64
  imagePullPolicy: IfNotPresent
  mainApplicationFile: local:///opt/spark-data/spark_batch_dataset.py
  sparkVersion: 3.5.4

  restartPolicy:
    type: Never

  arguments:             # âœ… Python script ì¸ì ì „ë‹¬ (PostgreSQL â†’ S3)
    # PostgreSQL ì—°ê²°ì •ë³´
    - "--pg-host"
    - "10.246.246.33"
    - "--pg-port"
    - "12345"
    - "--pg-db"
    - "testdb"
    - "--pg-user"
    - "dwnusa"
    - "--pg-table"
    - "smd_raw_data_lake"

    # S3 ì €ì¥ ê´€ë ¨
    - "--s3-bucket"
    - "s3a://mybucket/smd-dataset"
    - "--format"
    - "parquet"

    # ìµœê·¼ Nì¼ë§Œ ë°±ì—…
    - "--days"
    - "3"

  driver:
    cores: 1
    memory: 512m
    serviceAccount: spark-operator-spark
    volumeMounts:
      - name: data
        mountPath: /opt/spark-data

  executor:
    cores: 1
    instances: 4
    memory: 512m
    volumeMounts:
      - name: data
        mountPath: /opt/spark-data

  volumes:
    - name: data
      hostPath:
        path: /opt/spark/jobs
