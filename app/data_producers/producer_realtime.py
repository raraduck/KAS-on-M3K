#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import glob
import csv
import json
import time
import argparse
from datetime import datetime
from kafka import KafkaProducer
from kafka.admin import KafkaAdminClient, NewTopic
from kafka.errors import TopicAlreadyExistsError


# logger íŒŒì¼ë¡œ ì €ì¥
# try catch ìì„¸í•˜ê²Œ ì ìš©

# -------------------- í† í”½ ìƒì„± -------------------- #
def create_topic(bootstrap_servers, topic_name, num_partitions=3, replication_factor=1):
    admin_client = KafkaAdminClient(
        bootstrap_servers=bootstrap_servers,
        client_id='topic_creator'
    )

    topic = NewTopic(
        name=topic_name,
        num_partitions=num_partitions,
        replication_factor=replication_factor
    )

    try:
        admin_client.create_topics(new_topics=[topic], validate_only=False)
        print(f"âœ… í† í”½ ìƒì„± ì™„ë£Œ: {topic_name}")
    except TopicAlreadyExistsError:
        print(f"âš ï¸ í† í”½ '{topic_name}'ì€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")
    finally:
        admin_client.close()


# -------------------- JSON ì§ë ¬í™” -------------------- #
def json_serializer(data):
    """ë°ì´í„°ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì§ë ¬í™”"""
    return json.dumps(data).encode('utf-8')


# -------------------- CSV íŒŒì¼ ì œë„ˆë ˆì´í„° -------------------- #
def iter_smd_csv_rows(machine):
    """
    data/machine-*-*/ í•˜ìœ„ì˜ *_test.csv íŒŒì¼ì„ ìˆœíšŒí•˜ë©°
    ê° íŒŒì¼ì˜ í•œ ì¤„(row)ì„ yield
    """
    base_dir = os.path.dirname(os.path.abspath(__file__))
    data_pattern = os.path.join(base_dir, "data", machine, "*_test.csv")
    csv_files = sorted(glob.glob(data_pattern))

    if not csv_files:
        print(f"âš ï¸ CSV íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {data_pattern}")
        return

    for csv_path in csv_files:
        print(f"ğŸ“‚ ì½ëŠ” ì¤‘: {os.path.basename(csv_path)}")

        with open(csv_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                # CSVì˜ timestamp ëŒ€ì‹  ì „ì†¡ ì‹œê°ì„ ë®ì–´ì“°ê¸° (ì„ íƒ)
                numeric_row["send_timestamp"] = datetime.now().isoformat()
                numeric_row["machine"] = f"{machine}-test"
                # ê° í–‰ì„ float ë˜ëŠ” intë¡œ ë³€í™˜
                numeric_row = {k: try_parse_number(v) for k, v in row.items()}
                yield numeric_row


def try_parse_number(value):
    """ë¬¸ìì—´ì„ float/intë¡œ ë³€í™˜, ì‹¤íŒ¨ ì‹œ ê·¸ëŒ€ë¡œ ë°˜í™˜"""
    try:
        if "." in value or "e" in value or "E" in value:
            return float(value)
        else:
            return int(value)
    except Exception:
        return value


# -------------------- Kafka ì „ì†¡ ì½œë°± -------------------- #
def on_send_success(record_metadata):
    print(f"âœ… ì„±ê³µ: topic={record_metadata.topic}, partition={record_metadata.partition}, offset={record_metadata.offset}")

def on_send_error(excp):
    print(f"âŒ ì‹¤íŒ¨: {excp}")


# -------------------- ë©”ì¸ ë£¨í”„ -------------------- #
def main():
    # ì¸ì íŒŒì‹±
    parser = argparse.ArgumentParser(description='Kafka í”„ë¡œë“€ì„œ ì˜ˆì œ - ë©”ì‹œì§€ ìƒì„±')
    parser.add_argument('--topic', default='test-topic', type=str, help='ë©”ì‹œì§€ë¥¼ ë³´ë‚¼ í† í”½')
    parser.add_argument('--interval', default=60, type=int, help='ë©”ì‹œì§€ ì „ì†¡ ê°„ê²© (ë‹¨ìœ„ ì´ˆ)')
    parser.add_argument('--machine', default='machine-1-1', type=str, help='ì¸¡ì •í•  ë¨¸ì‹  ì´ë¦„ ex. machine-*-*')
    parser.add_argument('--bootstrap-servers', default='kafka.kafka.svc.cluster.local:9092',
                     type=str, help='Kafka ë¶€íŠ¸ìŠ¤íŠ¸ë© ì„œë²„')
    args = parser.parse_args()
    
    bootstrap_servers = args.bootstrap_servers.split(",") # ['kafka.kafka.svc.cluster.local:9092']
    topic_name = args.topic # "realtime-test-topic"

    create_topic(
        bootstrap_servers=bootstrap_servers,
        topic_name=topic_name,
        num_partitions=1,
        replication_factor=3
    )

    producer = KafkaProducer(
        client_id="machine-producer",   # âœ… í”„ë¡œë“€ì„œ ì‹ë³„ìš© ì´ë¦„
        bootstrap_servers=bootstrap_servers,
        key_serializer=str.encode,         # âœ… ë¬¸ìì—´ â†’ bytes ìë™ ë³€í™˜
        value_serializer=json_serializer,
        acks='all'
    )

    print("ğŸš€ Kafka Producer ì‹œì‘ (ë¬´í•œ ë°˜ë³µ). Ctrl+Cë¡œ ì¢…ë£Œ.")

    try:
        while True:  # ğŸ” ë¬´í•œ ë£¨í”„
            for message in iter_smd_csv_rows(args.machine):
                # Kafkaë¡œ ì „ì†¡
                future = producer.send(
                    topic_name, 
                    value=message, 
                    key=f"{args.machine}-test" # f"{args.machine}".encode("utf-8")
                )  # ë°˜ë“œì‹œ bytes í˜•ì‹
                future.add_callback(on_send_success).add_errback(on_send_error)

                print(f"ğŸ“¤ ì „ì†¡: {message}")
                time.sleep(args.interval)  # ì „ì†¡ ê°„ê²© ì¡°ì • ê°€ëŠ¥ (ë¶„ë‹¹ 1ê±´)
            
            # í•œ ë°”í€´ ë‹¤ ëŒì•˜ìœ¼ë©´ ëŒ€ê¸° í›„ ë‹¤ì‹œ ì‹œì‘
            print("ğŸ” CSV ì „ì²´ ì „ì†¡ ì™„ë£Œ. 60ì´ˆ í›„ ì¬ì‹œì‘...\n")
            time.sleep(args.interval)

    except KeyboardInterrupt:
        print("ğŸ›‘ í”„ë¡œë“€ì„œ ì¢…ë£Œ")
    finally:
        producer.flush()
        producer.close()


# -------------------- ì‹¤í–‰ -------------------- #
if __name__ == "__main__":

    main()
